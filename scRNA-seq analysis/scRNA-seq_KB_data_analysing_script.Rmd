---
title: "Analysing scRNA-seq KB data using scater and seurat"
owner: "Luna-Velez-lab"
date: "Documented 08-05-23"
output:
  html_document:
    df_print: paged
  pdf_document: default
---
This is a R Markdown file showing the workflow for analyzing scRNA-seq data that is already pre-processed by seq2science. Seq2science uses kalisto bustools which performs pseudoalignment on the scRNAseq reads and identifies spliced and unspliced reads. 
The results from the seq2science kalisto bustools analysis are the input for this workflow. 

This workflow has been created using our data as example. When you want to use this workflow for your own analysis you will need to change parts of the code to make it fit your data. 
This include: 
- Changing file/folder paths 
- Changing file names 
- Modifying manually set thresholds so they make sense for your data
- Changing metadata input variable for quality assessment as they might be different/ differently named for your data
- possibly making different decisions along the way based on your data and your preferences 
- Updating functions when neccesary, as they might be deprecated when you use a newer version of Scater (>1.14.0 ) or Seurat (>3.2.3)


#-----------------------------------#
## Installing required packages
#-----------------------------------#

When working on the server make sure that all required packages are present in the environment. (scRNAseq.yaml)
```{r, include = FALSE}

### Installing the important repositories:
# This should be done once 
# BiocManager can help you download packages:
# if (!requireNamespace("BiocManager", quietly = TRUE))
    # install.packages("BiocManager")

#if packages are not yet installed, install them using biocManager::install () or install.packages()
#The packages only need to be installed once and can be activated by running library function.

# BiocManager::install("biomaRt")
# BiocManager::install(c("SingleCellExperiment"))
# install.packages("mvoutlier")
install.packages("stringi")

### Loading the required packages
require("devtools")
library(ggplot2)
library(SingleCellExperiment)#package for creating structures for storing and manipulating single-cell genomics data, compatible with scater
library(scater)#A packages that can be used to perfroming quality control analysis scRNA-seq data
library(dplyr)#pacakges that can be used for manipulating tables
library(tidyr)#pacakges that can be used for manipulating tables
library(mvoutlier)
library(limma)
library(knitr)#to set working directory
library(Seurat)#package for among others normalizaing, scaling and visualisation of scRNA-seq data
library(RColorBrewer)
library(plot3D)
library(biomaRt)#packages that can be used to access BioMart database and dataset


### loading the required functions: read_kb_counts(), QC_umis_384plot(), QC_ERCC_384plot()
# These functions are created by Rebecca R. Snabel and can be found in the utils.R file on her scRNA-seq github (https://github.com/Rebecza/scRNA-seq/blob/main/analysis/utils.R)
# Get the 3 required functions from the utils.R file and create a seperate R file for each function.
# activate the created R files: 
source("/scratch/yquint/collection_old_R_pipelines/read_kb_counts.R")# Extracts the kb-python counts from the seq2science output direcotry 
source("/scratch/yquint/collection_old_R_pipelines/qc_umis_384plot.R")# Plotting function for plate QC 
source("/scratch/yquint/collection_old_R_pipelines/qc_ercc_384plot.R")# Plotting function for plate QC 

```

### setting up the working directory for all outputs and inputs using the R markdown
When saving results of the pipeline they can be found in this directory 
```{r, include=FALSE}
# Writing the path to a directory where you want your results folder to be placed in
dir <- "/path/to/directory/"

# The code below creates a results folder in the specified dir 
# The name of the results folder will be todaysdate_results
# When running this command on a different date, it will again create a new folder
dateoftoday <- gsub("-", "", as.character(Sys.Date()))
resultsdir <- paste(dir, dateoftoday, "_results_DESeq2/", sep = "")
# Use the following command to create the results folder When working with R in linux
system(paste("mkdir -p ", resultsdir))
# Use the following command to create the results folder when working with R in your computer
dir.create(file.path(resultsdir))

```

```{r "setup"}
# Set the working directory to the newly created results folder  
knitr::opts_knit$set(root.dir = normalizePath(resultsdir))
# When you want to set the working directory to a results folder that already exists
#workdir <- "path/to/resultsfolder"
#knitr::opts_knit$set(root.dir = normalizePath(workdir))
```


#-----------------------------------#
## Cleaning the counts table
#-----------------------------------#

### Creating the SingleCellExperiment object

The raw counts table along with the metadata of the cells (annotation table) needs to be stored within an Scater usable object. Scater will be used to look into the quality of the data and to help with filtering out low quality cells or genes.

# Loading the data
```{r loading dataset, echo = TRUE}
# loading spliced and unspliced count tables
# the read_kb_counts() uses the data inside the kalistobus results folder from the scRNAseq seq2scienc workflow to create the count tables
# the function requires 3 arguments:
# (1)the path to the seq2science kalistobus results folder, (2) the name of count assay you want to load (spliced vs unspliced ) and (3) the path to a barcode_file which needs to be a 2-column file with a well-id and its respective DNA barcode

spliced.data = read_kb_counts("/ceph/rimlsfnwi/data/molbio/vermeulen/vicky/scRNA_Tufts_J.B./results/kallistobus/", "spliced", "/ceph/rimlsfnwi/data/molbio/vermeulen/vicky/scRNA_Tufts_J.B./Scater-Seurat/barcode_384.tab")
unspliced.data = read_kb_counts("/ceph/rimlsfnwi/data/molbio/vermeulen/vicky/scRNA_Tufts_J.B./results/kallistobus/", "unspliced", "/ceph/rimlsfnwi/data/molbio/vermeulen/vicky/scRNA_Tufts_J.B./Scater-Seurat/barcode_384.tab")

# if you get an error like this: cannot open file 'Output/log.out/counts_unfiltered/spliced.mtx': Not a directoryError in open.connection(file) : cannot open the connection
# it means there is probably an additionl file in the kalistobus results folder that is not a folder and the read_kb_counts cannot read it.
# open the read_kb_counts.R file and modify the list.files arguments to include a pattern recognition:
# output_folders <- list.files(dir, pattern = "_output", recursive = FALSE, include.dirs = TRUE)
# run the command again 

# resulting count tables contain the raw read counts with genes (symbol) as rows and cells as columns 
```

```{r}
# Check if the spliced and unspliced dataset are consisting of the same (ordering of) cells:
identical(colnames(spliced.data),colnames(unspliced.data))
# Percentage of reads unspliced
sum(unspliced.data)/(sum(spliced.data)+sum(unspliced.data))

```
# Phenotable preparations
Create a cell metadata table from the colnames of the counts table or upload a metadata table
```{r phenotable}
###From colnames 
# Each column in the created count tables (spliced and unspliced) represents a single cell
# The read_kb_counts() function creates a colname for each cell by combining the name of the output file the cells sequencing results are in (seq2science kallisto bustools results folder) with the cells well ID
# If the names of the output files contain metadata (for example, plate and library data), this information can be extracted to create a cell meta-data table 

# The read_kb_counts.R function uses the name of the seq2science kallisto bustools results file + the well barcodes to set the colnames of the spliced and unspliced data
# Beause the results files include the word output, this will also end up in the colnames and needs to be removed as it is not part of the cell metadata
colnames(spliced.data) <- gsub("_output", "", colnames(spliced.data))
colnames(unspliced.data) <- gsub("_output", "", colnames(unspliced.data))

phenodata <- data.frame(row.names=colnames(spliced.data))
phenodata$names <- row.names(phenodata)
phenodata <- separate(phenodata, col = "names", into = c("Timepoint", "Plate", "Library", "Well"), sep = "_")#assign the correct names to the information stored in the colnames
#phenodata <- separate(phenodata, col = "names", into = c("sample_name", "Well"), sep = "_")


## Uploading it directly 
# If you have a metadata table already ready you can also upload it directly, making usre that a least one column in the metadat is identical to the colames of the count tables
# phenodata <- read.table("phenodata_table.txt", header=TRUE, sep = "\t")

```

```{r}
## If there isn't already, add a column with the unique cell ids: for example by combining plateID and wellID##
phenodata$cellidunique <- paste(phenodata$Plate, phenodata$Well, sep = "_" )
```

```{r setting the default data}

# The default data (from now on) will be the spliced dataset 
default.data <- spliced.data

```

# Plate Overviews

Sometimes wells are missing from the count tables (removed because they had no reads, no barcode). For analysis this is not important as they would have been excluded anyway, but for the diagnostics you would still like to see the well even if they are empty. In the plate QC code below the missing wells are identified and added as extra columns to the dataset.
```{r}
## Running plate QC: looking at the number of unique counts for each well in the 384-well plates, are there certain patterns?

# load the barcode_file
plate_order <- read.table("/ceph/rimlsfnwi/data/molbio/vermeulen/vicky/scRNA_Tufts_J.B./Scater-Seurat/barcode_384.tab", sep = "\t", col.names = c("well","barcode"))

# Make a vector with all plate numbers/names
platenrs <- unique(as.character(paste(phenodata$Timepoint, phenodata$Plate, phenodata$Library, sep = "_"))) 

pdf("PlateDiag_lndscp.pdf", paper = "USr")
# settings for the plate diagnostics pdf 
par(mfrow=c(2,2), mar = c(5,4,4,2) + 0.1, cex.main = 1)
# iterate over each plates, order cells in the order of visualization
for (plate in platenrs){
  # use the order of cells from the barcode file (this is A1, A2, A3, etc to P24)
  primer_order <- paste(plate, plate_order$well, sep="_")
  # Create a matrix with the genes that are in the spliced count table as rows and the missing wells as columns
  # Set the readcount inside the matrix to 0
  missing_wells <- primer_order[!primer_order %in% colnames(default.data)]
  cols_to_add <- data.frame(matrix(ncol = length(missing_wells), nrow = length(rownames(default.data))))
  colnames(cols_to_add) <- missing_wells
  cols_to_add[is.na(cols_to_add)] <- 0
  # Add the missing wells matrix to the spliced count table
  diag_plate <- cbind(as.data.frame( as.matrix(spliced.data[,grep(plate, colnames(default.data))])), cols_to_add)
  # phenodata contains same cellid entry + rowname as used in dataset
  cells_order <- colnames(diag_plate[,match(primer_order, colnames(diag_plate))])
  
  # match dataset cells order with wells in the visualization
  tmp <- as.matrix(diag_plate[,cells_order])
  QC_umis_384plot(tmp, paste(plate, "UMI_QC", sep = "_"))
  QC_ERCC_384plot(tmp[grep("^ERCC", rownames(diag_plate)),], paste(plate, "ERCC_QC", sep = "_"))
  print(colnames(tmp))
  rm(tmp)
}
dev.off()
```

# Remove plate from experiment

If (a) certain plate(s) or part of a plate show really low quality based on the QC plots create above, you can already remove them here using the code below.
Also when you have included test cells in the scRNAseq analysis that you want to omit for downstream analysis you can remove them here. 

```{r filtering out entries}
# checking the amount of cells in the dataset
# length(colnames(default.data))
# check how many cells you remove based on your critaria (In the example below these are the cells from a plate called 0001)
# length(colnames(default.data[,grepl("0001", colnames(default.data)) == TRUE]))
# filter the data
# spliced.data <- spliced.data[,!grepl("d28-", colnames(spliced.data)) == TRUE]
# unspliced.data <- unspliced.data[,!grepl("d28-", colnames(unspliced.data)) == TRUE]

# no. of plates:
length(colnames(default.data))/384

```
# Matching phenodata with the dataset ordering

```{r matching phenotable, echo = FALSE}
# Only take the entries that are matchable with the counttable entries:
pheno_matched <- phenodata[rownames(phenodata) %in% colnames(default.data ),]

pheno_ordered <- pheno_matched[match(colnames(default.data),rownames(pheno_matched)),]

#saveRDS(pheno_matched, "pheno_matched.rds")
#save the metadat table as a CSV file 
write.csv(phenodata, "phenodata_kbordered.csv")
```

```{r build SCE}
# df -> matrix -> SCE + phenodata 
count_matrix <- as.matrix(default.data)

sce <- SingleCellExperiment(assays = list(counts = count_matrix), colData = pheno_ordered, rowData = rownames(count_matrix))
```

```{r filtering empty entries, echo = FALSE}
# Checking if the dataset contains genes without a symbol name:
missing.name <- rownames(sce[is.na(rownames(counts(sce)))])
print(missing.name)
```

### Cleaning the expression matrix, setting thresholds and defining Spike-ins

Your raw count table (spliced) is a matrix now.
You can set thresholds for the removal of genes too lowly expressed in a too small amount of cells. 

```{r}

# Removing genes that are 0 in all cells
gene_tresh = 0
amount_cells_expr = 0

keep_feature <- rowSums(counts(sce) > gene_tresh) > amount_cells_expr
sce_filt <- sce[keep_feature,]

# Spike-in provide a measure of sensitivity and specificity of an RNA-Seq experiment
# You can define which cells are spike-ins (using patterns)
# Which pattern you need to use to extract the spik-in cell names can be different depending on the refrence genome that was used by kalsito bustools 
# Oftentimes the ERCCs start with the pefix ERCC- and mitochondrial genes start with the prefix MT- (human) or mt- (mouse):
#is_mito <- rownames(sce_filt)[grepl("^MT-", rownames(sce_filt))] #(there are 37 mitochondrial genes)
#is_ercc <- rownames(sce_filt)[grepl("^ERCC-", rownames(sce_filt))]

# But in the mm10 genome annotation for example the mitochondrial genes do not start with ^mt- + there are only 13 mitochondria genes. 
# If that is the case you need to make a string with the names of the mitochondrial genes present in your data to select them for analysis.
Mito = data.frame(first_column = c("ND1","ND2", "COX1", "COX2", "ATP8", "ATP6", "COX3", "ND3", "ND4L", "ND4", "ND5", "ND6", "CYTB"))

is_mito <- rownames(sce_filt)[rownames(sce_filt) %in% Mito$first_column]
is_ercc <- rownames(sce_filt)[grepl("^ERCC-", rownames(sce_filt))]

#Add the spike-ins information to the sce object
#Information is stored in sce_filt@rowRanges@elementMetadata@listData[["spike_in"]]
rowData(sce_filt)$spike_in <- (rownames(sce_filt) %in% is_mito) | (rownames(sce_filt) %in% is_ercc)
table(sce_filt@rowRanges@elementMetadata@listData[["spike_in"]])


# Calculate the quality metrics.
# Scater has these functions where you can check for % ERCC or MT (feature controls) in each cell, but also the ratios of genes.
#cellQC <-    perCellQCMetrics(sce_filt,subsets=list(MT=is_mito, ERCC=is_ercc))
#featureQC <- perFeatureQCMetrics(sce_filt)

sce_filt <- addPerCellQC(sce_filt, subsets=list(MT=is_mito, ERCC=is_ercc))
sce_filt <- addPerFeatureQC(sce_filt)


# In earlier version of the scater/singleCellExperiment packages they used different functions to identify spike-ins and calculate the QC metrics:
# However in newer versions the functions are depriced 
# isSpike(sce_filt, "MT") <- rownames(sce_filt)[rownames(sce_filt) %in% Mito$first_column] # to assign spike in idenity to features
# isSpike(sce_filt, "ERCC") <- grepl("^ERCC-", rownames(sce_filt)) #to assign spkie in idenity to features
# sce_filt <- calculateQCMetrics(
   #   sce_filt, feature_controls = list(
   #   ERCC = is_ercc, 
   #   MT = is_mito
   #   )
   # )
   # 

# To save the QC object 
saveRDS(sce_filt, "sce_QCMertics.rds")
```

Genes that had less than `r amount_cells_expr` cells with an expression of less than `r gene_tresh` were removed.
In dataset `r table(keep_feature)` are the cells that we keep.
With `r addPerCellQC` spike-ins were saved in the dataset and used for quality metrics calculations.

# Making histograms of the total number of RNA moleculse (UMIs) per cell

```{r}
#sce_filt <- readRDS("sce_QCMertics.rds")

#histogram of the total UMIS counts with a arbitrary red threshold line set at 500 counts
#You need to run the 3 lines below at the same time
hist(sce_filt$sum, breaks = 100)
sum_tresh = 500 #here you can change the arbetrary thershold in the histogram
abline(v = sum_tresh, col = "red")


# Looking at the amount of unique genes (features) per cell
# This included the number of spike-ins
# When there are a lot of UMIs(counts) but only a few genes these cells are most likely not of high quality. 
total_feat_tresh = 200
hist(sce_filt$detected, breaks = 100)
abline(v= total_feat_tresh, col = "red")


```
Histogram showing the total amounts of counts (x-axis) per proportion of cells (each bar). Red line at: `r sum_tresh` counts. 
Histogram showing the total amounts of genes (features) per proportion of cells. Red line at: `r total_feat_tresh` genes.


# Plotting spike-in data

These plots show the percentage of spike-ins against the total amount of reads that are found in each cell. A higher percentage of spike-in indicates a lower amount of endogenous genes found in the cell. In case of a high percentage of mitochondrial genes, it is likely that these cells were apoptotic. Also cells that are smaller will have relatively more spike-in allocated reads, therefore it does not only indicate unhealthy cells. If cells have low mitochondrial gene count and low count of any other gene but high ERCC counts they are debris and not cells.

```{r}

# Sometimes cells can have a NaN percentage of spike-in gene
# These should not be kept for downstream analysis 
# The code below exacts the names of these cells:
NaN_cells <- unique(c(colnames(sce_filt)[sce_filt$subsets_ERCC_percent == "NaN"], colnames(sce_filt)[sce_filt$subsets_MT_percent == "NaN"]))
# Removal of NaN spike-in cells:
sce_filt <- sce_filt[,!colnames(counts(sce_filt)) %in% NaN_cells]


#plotting the spike-in genes 
# label type of the cells
lab_col = "Timepoint"

plotColData(sce_filt,
            x = "detected", 
            y = "subsets_MT_percent", colour = lab_col)

plotColData(sce_filt,
            x = "detected", 
            y = "subsets_ERCC_percent", colour = lab_col)

multiplot(
  plotColData(sce_filt, y="sum", x="Timepoint"),
  plotColData(sce_filt, y="detected", x="Timepoint"),
  plotColData(sce_filt, y="subsets_ERCC_percent", x="Timepoint"),
  plotColData(sce_filt, y="subsets_MT_percent", x="Timepoint"),
  cols=2)

lab_col_2 = "Library"

plotColData(sce_filt,
            x = "detected", 
            y = "subsets_MT_percent", colour = lab_col_2)

plotColData(sce_filt,
            x = "detected", 
            y = "subsets_ERCC_percent", colour = lab_col_2)

multiplot(
  plotColData(sce_filt, y="sum", x="Library"),
  plotColData(sce_filt, y="detected", x="Library"),
  plotColData(sce_filt, y="subsets_ERCC_percent", x="Library"),
  plotColData(sce_filt, y="subsets_MT_percent", x="Library"),
  cols=2)

```

#------------------------------------------
## Filtering of death or unhealthy cells ##
#------------------------------------------

Using a manual and atomatic approach to filtering out low quality cells.
The automatic approach is based on a PCA on the quality metrics.

```{r}
### Manualy defining filtering criteria of the cells:
# Determine which thresholds make sense for your cells, check literature
# hESC-derived CMs should contain cells of approximatly the same size. 
# Cardiomyocytes are known to contain relatively many mitochondria, therefore a relatively high threshold is allowed.

filter_by_expr_features <- sce_filt$detected >= 200 #fitering out cells with a low number of expressed features
filter_by_sum <- sce_filt$sum >= 500 # filtering out cells with a low umi count
filter_by_ercc <- sce_filt$subsets_ERCC_percent < 25 # filtering out cells with a high percentage of ERCCs
filter_by_mt <- sce_filt$subsets_MT_percent < 40 #filtering out cells with a high percentage of mitochondrial genes

#Add a column to the cell metadata that states if a cell should be used FALSE or TRUE
#Based on the filters set above  
sce_filt$use <- (filter_by_expr_features 
         & # cells left with enough genes
           filter_by_sum 
         & # (number) cells left with enough counts
           filter_by_ercc 
         & #(number) cells left with enough endogenous RNA counts
           filter_by_mt)
           #(number) cells left with less than 40% mito genes 

#in total filters (number) cells out of the dataset
table(filter_by_expr_features)
table(filter_by_sum)
table(filter_by_ercc)
table(filter_by_mt)

# Result of manual filtering with set thresholds:
table(sce_filt$use)

```
#-----------------------#
## Filtering the genes ##
#-----------------------#
You do the filtering of the genes after selecting the healthy cells, because some genes might only be detected in poor quality cells

```{r}

# The reads consumed by the top 50 expressed genes:
plotHighestExprs(sce_filt)

# For the filtering of the genes of the example data the detectable expression is set to: if at least 2 cells contain more than 1 transcript of a gene.(>1]) >=2 )
# Threshold is depending on sequencing depth.
# With 1 million of cells use >1]) >=2 to prevent getting single unclustered cells, representing noise. In 1 million cells, 1 single cell with a unique profile is likely noise. 
# Scale 10x higher the threshold of the second number (cells) when 10x (1 million x10) more cells . 
# For a small experiment (of less than 300 cells per condition) a low threshold is ok, for example >0]) >=1  

# Dropout rate: A concept to considered in scRNAseq. Some genes are really lowly expressed by cells. These transcripts are more difficult to pick up by scRNA-sequencing resulting in a 0 read count when it is actual 1 in some cells and in others scRNA-seq was able to pick up the 1 transcript read. If one gene (for example Gp2) is absent,  other transcripts will cluster the cells together (some Gp2 positive, some not).

#stored the genes that are considered to be expressed in your dataset, in a vector called filter_genes.
filter_genes <- apply(
    counts(sce_filt), 
    1, 
    function(x) length(x[x > 1]) >= 2 # :  1 transcript of a gene in at least 2 cells
    )

genes_expressed <- sum(filter_genes==TRUE)
```


The next step is to select within the dataset the only information you want to keep for further analysis:
- Selecting only the healthy cells according to what you choose to create thresholds 
- Selecting only the genes considered to be expressed.
```{r}

# Add a column to the gene metadata (rowData) that states if a gene is expressed (either FALSE or TRUE) based on the filter set above
rowData(sce_filt)$use <- filter_genes
# Now the quality check-passing cells and genes are stored in the SCE-object in sce_filt$use selection of the counts table. 

# check how many cells you are now left with 
dim(sce_filt)
dim(sce_filt[rowData(sce_filt)$use, colData(sce_filt)$use])

# Create the quality-checked dataset:
sce_qc <- sce_filt[rowData(sce_filt)$use, colData(sce_filt)$use]

#save the subsetted sce object
saveRDS(sce_qc, "qc_counts.rds")

```



```{r filtered dataset: compare before/after filtering}
# create some histograms to see the difference in the dataset before and after filtering
# saved in a PDF format inside the results direcotry created at the beginning of this workflow
pdf("20200510_HIstograms_before+aftercellsFiltering.pdf")
par(mfrow=c(2,2))
hist(sce_filt$sum, breaks = 100)
abline(v = sum_tresh, col = "red")

hist(sce_filt$detected, breaks = 100)
abline(v= total_feat_tresh, col = "red")

hist(sce_qc$sum, breaks = 100)
abline(v = sum_tresh, col = "red")

hist(sce_qc$detected, breaks = 100)
abline(v= total_feat_tresh, col = "red")
dev.off()

pdf("20200510_MT+ERCC_before+aftercellsFiltering.pdf")
par(mfrow=c(2,2))
plotColData(sce_filt,
            x = "detected", 
            y = "subsets_MT_percent", colour = lab_col)

plotColData(sce_filt,
            x = "detected", 
            y = "subsets_ERCC_percent", colour = lab_col)
plotColData(sce_qc,
            x = "detected", 
            y = "subsets_MT_percent", colour = lab_col)

plotColData(sce_qc,
            x = "detected", 
            y = "subsets_ERCC_percent", colour = lab_col)
dev.off()

```



#-----------------------------
## Normalization in Scater
#-----------------------------

###Check for confounding factors
PCA on only the endogenous genes (so without the spike-ins) is used to evaluate the influence of the confounding factors.

```{r endogenous dataset for confounding factors}
# sce_qc <- readRDS("qc_counts.rds")

endo_genes <-!sce_qc@rowRanges@elementMetadata@listData[["spike_in"]] # endo_genes == Nnn spike-ins
table(endo_genes)#false are the number of spike-ins

# Make a object with only the endogenous genes to look for confounders
sce_endo <- sce_qc[endo_genes,] 
#reducedDim(sce_qc) <- NULL

#to check if the spike-ins are gone
plotHighestExprs(sce_endo)
#The line below creates a figure tthat shows the expression frequncy vs the mean where each dot represetns a gene. 
# mean: the mean count of the gene/feature across all cells; 
# detected: the percentage of cells with non-zero counts for each seperate gene; 
plotRowData(sce_endo, x = "mean", y= "detected")
```

run PCA
```{r PCA on raw data}
# Plotting the raw data without any transformation.
# The PCA per default uses the top 500 most variable genes of the dataset, changeable with the argument: ntop = 500.
sce_endo <- runPCA(                                             
  sce_endo, 
  ncomponents = 12,
  exprs_values = "counts" 
)


plotReducedDim(sce_endo, use_dimred = "PCA",   
               colour_by = "Library",
               size_by = "detected")
plotReducedDim(sce_endo, use_dimred = "PCA",   
               colour_by = "Timepoint",
               size_by = "detected")

# The PCA data is stored in the reducedDimNames as a "PCA_coldata" entry, if use_coldata = TRUE in runPCA(). If use_coldata = FALSE, this will be stored in "PCA". 
reducedDimNames(sce_endo)



```

# Raw log2-transformation
To compare with other normalization methods.
```{r raw log2-transformation}
assay(sce_endo, "logcounts_raw") <- log2(counts(sce_endo) + 1)

# plotReducedDim and plotPCA will do the same, with plotPCA you leave out the use_dimred="PCA" argument.
tmp <- runPCA(sce_endo, ncomponents = 50, exprs_values = "logcounts_raw")
# plot PCA after log2 transformation
plotPCA(tmp, 
        colour_by = "Library",
        size_by = "detected")
plotPCA(tmp, 
        colour_by = "Timepoint",
        size_by = "detected")
# plotPCA(sce_endo, ncomponents = 4,
         # colour_by = "Library")

# One can also run tSNE in similar ways with Scater.

# The logcounts_raw is not enough to account for the technical factors between the cells.

#save the sce object where the spike-ins are removed
saveRDS(sce_endo, "endo_counts.rds")
```

#-------------------------
## Normalization in Seurat
#-------------------------

#Make the seurat object, 'seuset'.
In Seurat you could filter the cells again. 
For this workflow the genes and cells are already filtered at this point. see "filtering of death or unhealthy cells"

```{r}
# sce_qc <- readRDS("qc_counts.rds")
# sce_endo <- readRDS("endo_counts.rds")
# pheno_matched <- readRDS("pheno_matched.rds")

#checking if the data changed:
#counts(sce_endo)[30:40,30:40]
#counts(sce_qc)[30:40,30:40]

#create a Seurat object 
#The meta.data argument is set to include the first 7 columns of the sce_endo metadata: which is the case of the example data are Timepoint, Plate, Library, Well, cellidunique, is_cell_control, detected
seuset <- CreateSeuratObject(counts = counts(sce_endo), assay = "sf", meta.data = as.data.frame(colData(sce_endo)[,1:7]))


#you can also use the pheno_matched table that was created for the sce object to add metadata to the seurat object
#seuset <- AddMetaData(seuset, metadata = pheno_matched)

```

```{r}
# looking into the dataset: for example number of features/counts by timepoint, number of features/count by library  
VlnPlot(
    object = seuset, 
    features = c("nFeature_sf"), 
    split.by = "Timepoint"
)
VlnPlot(
    object = seuset, 
    features = c("nCount_sf"), 
    split.by = "Timepoint"
)
VlnPlot(
    object = seuset, 
    features = c("nFeature_sf"), 
    split.by = "Library"
)
VlnPlot(
    object = seuset, 
    features = c("nCount_sf"), 
    split.by = "Library"
)

#expression of a gene of interest by Library or Timepoint
VlnPlot(
  object = seuset, 
    features = c("Dclk1"), #A gene of interest
    split.by = "Library"
)

VlnPlot(
  object = seuset, 
    features = c("Dclk1"), 
    split.by = "Timepoint"
)

#number of counts vs number of features
FeatureScatter(
    object = seuset, 
    feature1 = "nCount_sf", 
    feature2 = "nFeature_sf"
)

```

```{r}
# Seurat normalization: "a global-scaling normalization method LogNormalize that normalizes the gene expression measurements for each cell by the total expression, multiplies this by a scale factor (10,000 by default), and log-transforms the result." This will removed the effect of size on the total number of counts. 

#Fist, assign the non normalized seurat object to a seu object
#this object will be used to create a combined spliced and unspliced seurat object later
seu <- seuset

seuset.norm <- NormalizeData(
    object = seuset, 
    normalization.method = "LogNormalize", 
    scale.factor = 10000
)

VlnPlot(
    object = seuset, 
    features = c("nFeature_sf"), 
    split.by = "Timepoint"
)
VlnPlot(
    object = seuset, 
    features = c("nCount_sf"), 
    split.by = "Timepoint"
)
VlnPlot(
    object = seuset, 
    features = c("nFeature_sf"), 
    split.by = "Library"
)
VlnPlot(
    object = seuset, 
    features = c("nCount_sf"), 
    split.by = "Library"
)
VlnPlot(
  object = seuset, 
    features = c("Onecut2"), 
    split.by = "Library"
)
VlnPlot(
  object = seuset, 
    features = c("Onecut2"), 
    split.by = "Timepoint"
)
FeatureScatter(
    object = seuset, 
    feature1 = "nCount_sf", 
    feature2 = "nFeature_sf"
)

#save the normalized seurat object
saveRDS(seuset.norm, "seusetnorm.rds")

# If you wish to export your normalized and transformed counts then:
#norm_log_counts_matrix <- as.matrix(seuset.norm[["RNA"]]@data)
#write.table(norm_log_counts_matrix, file = "Norm_log_counts_matrix_Seurat.txt",sep = "\t",
#            row.names = TRUE, col.names = NA, quote = FALSE)

```
#----------------------------------------------------#
## compare QC before and after seurat normalization ##
#----------------------------------------------------#

To check how the normalization changed the data, a new SingleCellExperiment object can be created. This to enable the use of scater again. This is just to check if the QCMetrics are the same after Seurat normalization. 
```{r seurat objects to sce} 

# Only take the entries that are matchable with the counttable entries:
pheno_matchedseuset <- phenodata[rownames(phenodata) %in% colnames(seuset@assays$sf@data),]
pheno_orderedseuset <- pheno_matchedseuset[match(colnames(seuset@assays$sf@data),rownames(pheno_matchedseuset)),]

count_matrixseuset <- as.matrix(seuset@assays$sf@data)

sce_seunorm <- SingleCellExperiment(assays = list(counts = count_matrixseuset), colData = pheno_orderedseuset, rowData = rownames(count_matrixseuset))
# This is a little trick to let scater know that there are actually logcounts in the dataset.
assay(sce_seunorm, "logcounts") <- counts(sce_seunorm)
#check that they indeed are the same
counts(sce_seunorm)[1:20,1:10]
logcounts(sce_seunorm)[1:20,1:10]
#check that they indeed are the same
#counts(sce_seunorm)[1:20,1:10]
#logcounts(sce_seunorm)[1:20,1:10]


# Calculate the quality metrics:
sce_seunorm <- addPerCellQC(sce_seunorm)
sce_seunorm <- addPerFeatureQC(sce_seunorm)


```

# Identifying the variation caused by each confounding factor
```{r check confounders in raw dataset}
#sce_endo <- readRDS("endo_counts.rds")

# This function is looking at a PCA analysis in the data object and checks to what extend the variables that are put in, are explaining this variance.
# The function getExplanatoryPCs needs an assay logcounts, therefore the 'raw' logcounts are put in there, after which they need to be removed again.
logcounts(sce_endo) <- assay(sce_endo, "logcounts_raw")
mat_expl <- getExplanatoryPCs(sce_endo, variables = c("detected", "sum", "Library", "Timepoint", "subsets_ERCC_percent", "subsets_MT_percent"))
plotExplanatoryPCs(mat_expl, npcs_to_plot = 30, variable = "Library")

# remove the raw logcounts (a simple log2) from the assay logcounts again:
logcounts(sce_endo) <- NULL
assays(sce_endo)

# Fitting a linear model regressing expression values against just that variable, which computes a marginal R2, .
# this analysis indicated the explanatory power of the variables for the genes tested. 
plotExplanatoryVariables(sce_endo, 
                         exprs_values = "counts",
                         variables = c("detected", "sum",
                                       "Library", "Timepoint", "subsets_ERCC_percent", "subsets_MT_percent"))

```


```{r}
# Confounder influence check again but now for the new nomralized sce:
mat_explseuset <- getExplanatoryPCs(sce_seunorm, 
                                variables = c("detected", "sum",
                                "Library", "Timepoint"))
plotExplanatoryPCs(mat_explseuset, npcs_to_plot = 50, variable = "Library")
#mat_explseuset

# Show the variance explained by confounders after normalization methods:
plotExplanatoryVariables(sce_endo, 
                         exprs_values = "counts",
                         variables = c("detected", "sum",
                                       "Library", "Timepoint", "subsets_ERCC_percent", "subsets_MT_percent"))
plotExplanatoryVariables(sce_seunorm, 
                         variables = c("detected", "sum",
                                       "Library", "Timepoint"))

```

```{r}
# running PCA on the normalized counts
sce_seunorm <- runPCA(
  sce_seunorm, ncomponents = 20,
  exprs_values = "counts" 
)

```


```{r}
# plotting again the PCA's on raw-transformed and normalized values
# raw log-transformation.
tmp <- runPCA(sce_endo, ncomponents = 50, exprs_values = "counts")

# PCA plot after log2 transformation
plotPCA(tmp, 
        colour_by = "Library",
        size_by = "detected")
plotPCA(tmp, 
        colour_by = "Timepoint",
        size_by = "detected")


# PCA plot after seurat normalization
plotPCA(sce_seunorm,
               colour_by = "Library",
               size_by = "detected")
plotPCA(sce_seunorm,
               colour_by = "Timepoint",
               size_by = "detected")

```

#--------------------------------------------------------#
## Build Seurat object with unspliced and spliced assay ##
#--------------------------------------------------------#

To build the unspliced assay first select the same cells and genes as the filtered spliced dataset

```{r build SCE 2}
#sce_endo <- readRDS("endo_counts.rds")
cells_use <- colnames(sce_endo)
genes_use <- rownames(sce_endo)

#subset the spliced and unspliced data
spliced.data <- spliced.data[genes_use,cells_use]
default.data <- spliced.data
unspliced.data <- unspliced.data[genes_use,cells_use]
pheno_ordered <- pheno_ordered[cells_use,]#also subset the Metadata

#create a singleCellExperiment object using the subsetted unspliced data
sce_us <- SingleCellExperiment(assays = list(counts = as.matrix(unspliced.data)), colData = pheno_ordered, rowData = rownames(unspliced.data))

# Calculate the quality metrics:
sce_us <- addPerCellQC(sce_us)
sce_us <- addPerFeatureQC(sce_us)

# Arbitrary thresholds:
# Looking at the total number of RNA molecules per sample
hist(sce_us$sum, breaks = 100)
abline(v = sum_tresh, col = "red")

# Looking at the amount of unique genes per sample
# This is the amount with ERCC included.
hist(sce_us$detected, breaks = 100)
abline(v= total_feat_tresh, col = "red")


pdf("Histograms_before+aftercellsFiltering_UnsplicedReads.pdf")
par(mfrow=c(2,2))
hist(sce_us$sum, breaks = 100)
abline(v = sum_tresh, col = "red")
hist(sce_us$detected, breaks = 100)
abline(v= total_feat_tresh, col = "red")

dev.off()

```

#add the unspliced matrix to the seu object that already contains the spliced counts data

```{r}
unspliced_match <- as.matrix(unspliced.data)

#add the unspliced count table as an assy named "uf" to the already exising seruat object seu
seu[["uf"]] <- CreateAssayObject(counts = unspliced_match)

seu <- NormalizeData(
    object = seu, assay = "sf", #spliced countable 
    normalization.method = "LogNormalize", 
    scale.factor = 10000
)
seu <- NormalizeData(
    object = seu, assay = "uf", #unspliced countable 
    normalization.method = "LogNormalize", 
    scale.factor = 10000
)


saveRDS(seu, "seusetnorm_sf_uf.rds")

```

#----------------------------------------------------------------#
# Highly variable genes & Scaling of the gene expression values ##
#----------------------------------------------------------------#

First idenifying the highly variable genes
```{r}
# seu <- readRDS(seusetnorm_sf_uf.rds")
# FindVariableFeatures plots the dispersion (= a normalized measure of cell-to-cell variation), as a function of average expression for each gene. In other words: Which genes are expressed high or low in some cells compared to the average expression across all cells. 
# You can test different cutoffs to identify which is better.

seu <- FindVariableFeatures(
    object = seu, assay = "sf",
    selection.method = "vst",
    nfeatures = 1000)

seu <- FindVariableFeatures(
    object = seu, assay = "uf",
    selection.method = "vst",
    nfeatures = 1000)

# top 10 most variable genes
top20 <- head(VariableFeatures(seu, assay = "sf"), 20)

# plot variable features with labels:
plot1 <- VariableFeaturePlot(seu)
plot2 <- LabelPoints(plot = plot1, points = top20, repel = TRUE)
plot2
plot3 <- VariableFeaturePlot(seu, assay = "uf")
plot4 <- LabelPoints(plot = plot3, points = top20, repel = TRUE)
plot4
# Preferable removing the genes that are highly expressed but with a low variance.
length(x = seu@assays$sf@var.features)
seu[["sf"]]@var.features[1:10]


#save the seurat object that now contains the highly variable genes
saveRDS(seu, "seusetnorm_hvg_sf_uf.rds")

```
#scaling the data

Scaling the data makes it usable for dimensional reduction 

Sometimes variance between cells can be introduced by difference in cell cycle stages of the cell. The following chunk of code predicts the cell cycle stage of each cells based on gene expression and adds this information to the metadata compartment of the seurat object. This information can then be used to regress the data based on cell cycle phase: to remove the variance between the cells that is introduced by this phenomenon. 
```{r}
#seu <- readRDS("seusetnorm_hvg_sf_uf.rds")

# The example scRNA-seq data is from mouse
# The gene sets containing a list of genes indicative of the different cell cycle phases contain human gene symbols
# Function to convert human to mouse gene names:
convertHumanGeneList <- function(x){
 
human = useMart("ensembl", dataset = "hsapiens_gene_ensembl", host = "https://dec2021.archive.ensembl.org/")
mouse = useMart("ensembl", dataset = "mmusculus_gene_ensembl", host = "https://dec2021.archive.ensembl.org/")
 
genesV2 = getLDS(attributes = c("hgnc_symbol"), filters = "hgnc_symbol", values = x , mart = human, attributesL = c("mgi_symbol"), martL = mouse, uniqueRows=T)
 
humanx <- unique(genesV2[, 2])
 
# as a check print the first 6 genes found to the screen
print(head(humanx))
return(humanx)
}

#Using the function to create two cell cycle phases lists of genes containing mouse gene symbols (S and G2M)
#the cc.gene.updated.2019 is part of the seurat package
m.s.genes <- convertHumanGeneList(cc.genes.updated.2019$s.genes)
m.g2m.genes <- convertHumanGeneList(cc.genes.updated.2019$g2m.genes)

# give identities (phase S, G2M or G1) to cells, without modifying the orig.ident.
# Head to view cell cycle scores and phase assignments. Create variable to regress for each assay but probably scale (separately) with same var.to.regress (CC.Difference_sf for instance).

#first the spliced assay
seu <- CellCycleScoring(seu, assay = "sf", s.features = m.s.genes, g2m.features = m.g2m.genes, set.ident = FALSE)
head(seu[[]])

write.table(seu[[]], file = "Cell_cycle_score_sf_Seurat.txt",sep = "\t",
            row.names = TRUE, col.names = NA, quote = FALSE)

seu$CC.Difference_sf <- seu$S.Score - seu$G2M.Score
head(seu[[]])

#unslpiced assay 
seu <- CellCycleScoring(seu, assay = "uf", s.features = m.s.genes, g2m.features = m.g2m.genes, set.ident = FALSE)
head(seu[[]])

write.table(seu[[]], file = "Cell_cycle_score_uf_Seurat.txt",sep = "\t",
            row.names = TRUE, col.names = NA, quote = FALSE)

seu$CC.Difference_uf <- seu$S.Score - seu$G2M.Score
head(seu[[]])

#save the seurat-object with the additional cell cycle data
saveRDS(seuset.norm, "seusetnormMetaCC.rds")
write.table(seu[[]], file = "Cell_cycle_score_sf_uf_Seurat.txt",sep = "\t",
            row.names = TRUE, col.names = NA, quote = FALSE)
```

#scale the data
```{r}

#regress based on variables that introduce unwanted variance to the data (previously determined by the qc steps)
#The default is to scale only the variable_features, but in the example below it does it for all genes.
all.genes <- rownames(seuset) #using the spliced seurat object to obtain the list of all genes

seu <- ScaleData(
    object = seu, 
    assay = "sf",
    features = all.genes,
    vars.to.regress = c("nCount_sf", "nFeature_sf") #variables to regress by 
)

seu <- ScaleData(
    object = seu, 
    assay = "uf",
    features = all.genes,
    vars.to.regress = c("nCount_sf", "nFeature_sf") #variables to regress by 
)

#save the scaled seurat object
saveRDS(seu, "seusetnorm_scaled_sf_uf.rds")


```

## Running PCA analysis on the scaled data
```{r}
# seuset <- readRDS("seusetnorm_scaled_sf_uf.rds")
seuset.norm <- seu

DefaultAssay(seuset.norm) <- "sf"

seuset.norm <- RunPCA(seuset.norm, 
                      features = VariableFeatures(object = seuset.norm),
                      ndims.print = 1:5, 
                      nfeatures.print = 5
                      )
length(seuset.norm[["sf"]]@var.features)
length(seuset.norm[["uf"]]@var.features)

```

## Visualizing PCA results:
plots are saved in a pdf file 
```{r}

VizDimLoadings(object = seuset.norm, dims = 1:40, reduction = "pca")
pdf("VizDim_PCs1-40.pdf", width = 20, height = 20)
dev.off()
#If you see mt or ERCC in the plots something went wrong.

#to help with determining the PCs to include in the analysis 
DimPlot(object = seuset.norm, reduction = "pca")


pdf("Dimheatmap_PCs1-35.pdf", width = 20, height = 20)
DimHeatmap(object = seuset.norm, dims = 1:35, cells = 500, balanced = TRUE)
dev.off()
```

## Perform JackStraw Permutations to find significant PCs

```{r}
# seuset.norm <- JackStraw(seuset.norm, num.replicate = 100)
# seuset.norm <- ScoreJackStraw(seuset.norm, dims = 1:20) 
# 
# #save the plot 
# JackStrawPlot(seuset.norm, dims = 1:20)
# pdf("JackStrawPlot_PCs1-12.pdf", width = 20, height = 20)
# dev.off()

```

## Plotting Elbow plot to identify significant PCs
This plot displays the standard deviations of the PCs

```{r}

pdf("20191009_ElbowPlot_PCs1-35.pdf", width = 20, height = 20)
ElbowPlot(seuset.norm, ndims = 35)
dev.off()
```

Based on the heatmaps, elbow (as well as the JackStraw) the PCs that are insteresting for further analysis can be identified. 

```{r}
# Saving the dataset with the normalized, scaled and identified HVGs 
saveRDS(seuset.norm, "seusetnorm_hvg_scaled_PCA_sf_uf.rds")

```


#------------------------------#
## Idenifying Seurat Clusters ##
#------------------------------#
Seurat v3 applies a graph-based clustering approach, in which the cells are embedded in a graph structure (for example a K-nearest neighbor graph), with edges between the cells with similar feature expression patterns (determined with euclidean distances in PCA space and overlap within local neighborhoods, as determined with Jaccard similarity). The cells are then tried to partition into quasi-cliques or communities.

Louvain clustering is used after, to iteratively group cells together
```{r clustering }
seuset.norm <- readRDS("seusetnorm_hvg_scaled_PCA_sf_uf.rds")

# Calculating the distances and finding the neighbors:
seuset.norm <- FindNeighbors(seuset.norm, dims = 1:20)
seuset.norm <- FindClusters(seuset.norm, resolution = 1)
head(Idents(seuset.norm), 10)
# Number of nodes: 
# Number of edges: 
# Number of communities: 

#save the cluster metadata
Metadata_Clust_matrix <- as.matrix(seuset.norm@meta.data)
write.table(Metadata_Clust_matrix, file = "Metadata_Clust_matrix.txt",sep = "\t",
            row.names = TRUE, col.names = NA, quote = FALSE)
```

#Non-linear dimensional reduction UMAP
```{r running UMAP}
#run UMAP on the data 
seuset.norm <- RunUMAP(seuset.norm, dims = 1:20)
saveRDS(seuset.norm, "seusetnorm_UMAP.rds")

``` 

```{r}
#seuset.norm <- readRDS("seuset_UMAP.rds")
#plot the umap 
DimPlot(object = seuset.norm, reduction = "umap", label = TRUE, pt.size = 0.5 + NoLegend())
DimPlot(object = seuset.norm, reduction = "umap", group.by = "Timepoint", label = TRUE, pt.size = 0.5 + NoLegend())
DimPlot(object = seuset.norm, reduction = "umap", group.by = "library", label = TRUE, pt.size = 0.5 + NoLegend())

#create some pdfs
pdf("UMAP_res1_5_clusts.pdf", width = 10, height = 5)
DimPlot(seuset, reduction = "umap")
dev.off()
# 


pdf("UMAP_res1_5_timepoints.pdf", width = 10, height = 5)
DimPlot(seuset, reduction = "umap", group.by = "Timepoint")
dev.off()

##check for cell markers of interest within the data
#feature plots showing the expression of genes of interest in the UMAP
FeaturePlot(seuset.norm, features= c("Onecut2", "Hes1", "Relb", "Hnf4a", "Hnf4g", "spib"), cols=c("lightgrey","red4"), pt.size = 0.5, min.cutoff = 'q1')


#violin plots showing the expression of genes of interest for each group specified by the group.by argument
VlnPlot(object = seuset.norm, features = c("Nfkb2", "Tnfrsf11a", "Il4i1", "Lgr5", "Spib", "Onecut2"), ncol = 2, group.by = "Condition")


#redgePlot showing the expression of genes of interest for each group specified by the group.by argument 
RidgePlot(object = seuset.norm, features = c("Tnfrsf11a", "Anxa5", "Lgr5", "Spib", "Onecut2", "Nfkb2"), ncol = 2, group.by = "Condition")

# If you would like to check for correlations between genes of interest:
FeatureScatter(seuset.norm, "Il4i1", "Spib", slot = "counts")
```


#---------------------------------------------#
## Finding differentially expressed features ##
#---------------------------------------------#


```{r DE genes clusters}
# min.pct ; minim percentage of the cells in a cluster that must expressed a certain gene to be considered a differential expressed cluster gene. 
seuset.markers <- FindAllMarkers(seuset.norm, only.pos =TRUE, min.pct = 0.25, logfc.threshold = 0.25)
#show the two genes with the higherst avg_logFC for each cluster 
seuset.markers %>% group_by(cluster) %>% top_n(n = 2, wt = avg_logFC)
```

```{r heatmap DE genes}
top10 <- seuset.markers %>% group_by(cluster) %>% top_n(n = 10, wt = avg_logFC)
top20 <- seuset.markers %>% group_by(cluster) %>% top_n(n = 20, wt = avg_logFC)
top100 <- seuset.markers %>% group_by(cluster) %>% top_n(n = 100, wt = avg_logFC)
DoHeatmap(seuset.norm, features = top10$gene, group.by = "seurat_clusters") + NoLegend()

# If you wish to download the list of markers per cluster, set the ident.1 argument to the cluster of interest
Cluster0 = FindMarkers(seuset.norm, ident.1 = 0, min.pct = 0.25)
write.table(Cluster0, file = "Cluster0.txt", sep = "\t",
            row.names = TRUE, col.names = TRUE)

Cluster5 = FindMarkers(seuset.norm, ident.1 = 5, min.pct = 0.25)
write.table(Cluster5, file = "Cluster5.txt", sep = "\t",
            row.names = TRUE, col.names = TRUE)

``` 

 Additional information you can can extract from the seuset.norm object
 
```{r} 

#number of cell per cluster
table(seuset.norm@meta.data[["seurat_clusters"]])


#number of cells per library
table(seuset.norm@meta.data[["Library"]])


#extracting the number of cells that express a gene of interest within each clusters (example=Nfkb2)
NfKb2_cells <- subset(seuset.norm, features="Nfkb2")
NfKb2_cells@meta.data[["Nfkb2expression"]]<- colSums(NfKb2_cells[["RNA"]]@counts) !=0
table(NfKb2_cells@meta.data[["Nfkb2expression"]], NfKb2_cells@meta.data[["seurat_clusters"]])
NfKb2_cells@meta.data[["Nfkb2expression"]]<- NULL
#         0   1   2   3   4   5   6   7
#FALSE 134  85  33  23  49  10  29  22
#TRUE   26  18  44  53   7  44   7   6

#or if you want only the TRUE
#use this function
n_cells_in_cluster_expresssing_gene <- function(x) {
  cells_expressing_gene <- subset(seuset.norm, features=x)
  cells_expressing_gene@meta.data[["gene_expression"]]<- colSums(cells_expressing_gene[["RNA"]]@counts) !=0
  Idents(cells_expressing_gene) <- "gene_expression"
  subset <- subset(cells_expressing_gene, ident=TRUE)
  return(table(subset@meta.data[["seurat_clusters"]]))
  cells_expressing_gene@meta.data[["gene_expression"]] <- NULL
}

```


```{r compile, eval=FALSE}

library(knitr)

knit('knitr-minimal.Rmd')

```


